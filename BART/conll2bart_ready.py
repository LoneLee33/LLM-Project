{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abebd28-78ef-42e3-bbb7-d4ffe2e700a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "\n",
    "# Map the CoNLL label to the XML tag you want in the BART input\n",
    "TAG_MAPPING = {\n",
    "    'VAR':       'var',\n",
    "    'PARAM':     'param',\n",
    "    'OBJ_NAME':  'obj_name',\n",
    "    'OBJ_DIR':   'obj_dir',\n",
    "    'CONST_DIR': 'const_dir',\n",
    "    'LIMIT':     'limit',\n",
    "}\n",
    "\n",
    "PUNCTUATION = {'.', ',', '!', '?', ';', ':'}\n",
    "CONTRACTIONS = {\"'s\", \"n't\", \"'re\", \"'ll\", \"'ve\", \"'d\", \"'m\"}\n",
    "\n",
    "def read_conll(path):\n",
    "    \"\"\"\n",
    "    Returns a list of (tokens, tags) for each sentence in the CoNLL file.\n",
    "    Sentences are separated by blank lines or -DOCSTART- lines.\n",
    "    \"\"\"\n",
    "    sents, tokens, tags = [], [], []\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            # new-sentence boundary\n",
    "            if not line or line.startswith('-DOCSTART-'):\n",
    "                if tokens:\n",
    "                    sents.append((tokens, tags))\n",
    "                    tokens, tags = [], []\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            token, tag = parts[0], parts[-1]\n",
    "            tokens.append(token)\n",
    "            tags.append(tag)\n",
    "        # final sentence\n",
    "        if tokens:\n",
    "            sents.append((tokens, tags))\n",
    "    return sents\n",
    "\n",
    "def join_tokens(tokens):\n",
    "    \"\"\"\n",
    "    Glue tokens back into a string, avoiding spaces before punctuation or\n",
    "    before common English contractions.\n",
    "    \"\"\"\n",
    "    out = ''\n",
    "    for tok in tokens:\n",
    "        if not out:\n",
    "            out = tok\n",
    "        elif tok in PUNCTUATION or tok in CONTRACTIONS:\n",
    "            out += tok\n",
    "        else:\n",
    "            out += ' ' + tok\n",
    "    return out\n",
    "\n",
    "def tokens_to_tagged_text(tokens, tags):\n",
    "    \"\"\"\n",
    "    Walk the token/tag sequence, wrap B‑ spans in the corresponding XML tag,\n",
    "    leave O tokens as‑is.\n",
    "    \"\"\"\n",
    "    i, n = 0, len(tokens)\n",
    "    out_tokens = []\n",
    "    while i < n:\n",
    "        tag = tags[i]\n",
    "        if tag.startswith('B-'):\n",
    "            label = tag[2:]\n",
    "            xml = TAG_MAPPING.get(label)\n",
    "            # collect the full span\n",
    "            span = [tokens[i]]\n",
    "            i += 1\n",
    "            while i < n and tags[i] == 'I-' + label:\n",
    "                span.append(tokens[i])\n",
    "                i += 1\n",
    "            span_text = join_tokens(span)\n",
    "            out_tokens.append(f'<{xml}>{span_text}</{xml}>')\n",
    "        else:\n",
    "            out_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "    return join_tokens(out_tokens)\n",
    "\n",
    "def main(conll_path, bart_ready_in, bart_ready_out):\n",
    "    # 1) load your existing BART‑ready file (to grab 'output' fields)\n",
    "    outputs = []\n",
    "    with open(bart_ready_in, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            rec = json.loads(line)\n",
    "            outputs.append(rec['output'])\n",
    "\n",
    "    # 2) parse the CoNLL file\n",
    "    sents = read_conll(conll_path)\n",
    "    assert len(sents) == len(outputs), (\n",
    "        f\"Mismatch: {len(sents)} sentences vs. {len(outputs)} records\"\n",
    "    )\n",
    "\n",
    "    # 3) combine and write\n",
    "    with open(bart_ready_out, 'w', encoding='utf-8') as out:\n",
    "        for (tokens, tags), target in zip(sents, outputs):\n",
    "            inp = tokens_to_tagged_text(tokens, tags)\n",
    "            json.dump({'input': inp, 'output': target}, out, ensure_ascii=False)\n",
    "            out.write('\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = argparse.ArgumentParser(\n",
    "        description=\"Convert CoNLL NER output to BART-ready JSONL\"\n",
    "    )\n",
    "    p.add_argument('--conll',       required=True, help=\"Path to train.txt\")\n",
    "    p.add_argument('--bart-ready-in',  required=True,\n",
    "                   help=\"Existing train_bart_ready.jsonl (for output fields)\")\n",
    "    p.add_argument('--bart-ready-out', required=True,\n",
    "                   help=\"Where to write the new JSONL\")\n",
    "    args = p.parse_args()\n",
    "    main(args.conll, args.bart_ready_in, args.bart_ready_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
