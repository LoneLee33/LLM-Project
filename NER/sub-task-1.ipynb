{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb393071-c5e1-49d3-b6a2-db4dfc12ff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label set: ['B-CONST_DIR', 'B-LIMIT', 'B-OBJ_DIR', 'B-OBJ_NAME', 'B-PARAM', 'B-VAR', 'I-CONST_DIR', 'I-LIMIT', 'I-OBJ_NAME', 'I-PARAM', 'I-VAR', 'O']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3d7053c900432d97200f6f5f464f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/714 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8689dcd3bec4253b0a0855484cd9d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4feb1d057b2344bf9a2bbee9fd71e195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "D:\\Anaconda\\envs\\env_opt\\Lib\\site-packages\\torch\\cuda\\__init__.py:235: UserWarning: \n",
      "NVIDIA GeForce RTX 5070 Ti with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 5070 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lonel\\AppData\\Local\\Temp\\ipykernel_43400\\2866782259.py:164: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 01:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.922800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.195900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation: {'eval_loss': 0.2724146246910095, 'eval_precision': 0.8777260018639329, 'eval_recall': 0.8166840097121054, 'eval_f1': 0.8461054712065402, 'eval_accuracy': 0.938971528362491, 'eval_runtime': 1.6785, 'eval_samples_per_second': 172.778, 'eval_steps_per_second': 11.32, 'epoch': 3.0}\n",
      "Tokens: ['-DOCSTART-']\n",
      "Predicted Labels: ['O']\n",
      "\n",
      "Tokens: ['A', 'flooring', 'company', 'produces', 'engineered', 'hardwood', 'and', 'vinyl', 'planks', '.', 'Their', 'sales', 'forecasts', 'show', 'an', 'expected', 'demand', 'of', 'at', 'least', '20,000', 'square', 'foot', 'of', 'hardwood', 'and', '10,000', 'square', 'feet', 'of', 'vinyl', 'planks', 'each', 'week', '.', 'To', 'satisfy', 'a', 'shipping', 'contract', ',', 'a', 'total', 'of', 'at', 'least', '60,000', 'square', 'feet', 'of', 'flooring', 'much', 'be', 'shipped', 'each', 'week', '.', 'Due', 'to', 'a', 'labor', 'shortage', 'issue', ',', 'no', 'more', 'than', '50,000', 'square', 'feet', 'of', 'hardwood', 'and', '30,000', 'square', 'feet', 'of', 'vinyl', 'can', 'be', 'produced', 'weekly', '.', 'If', 'a', 'square', 'foot', 'of', 'hardwood', 'flooring', 'yields', 'a', 'profit', 'of', '$', '2.5', 'and', 'a', 'square', 'foot', 'of', 'vinyl', 'planks', 'produces', 'a', '$', '3', 'profit', ',', 'how', 'many', 'of', 'each', 'type', 'of', 'flooring', 'should', 'be', 'made', 'weekly', 'to', 'maximize', 'the', 'company', \"'s\", 'profit', '?']\n",
      "Predicted Labels: ['O', 'O', 'O', 'O', 'O', 'B-VAR', 'O', 'B-VAR', 'I-VAR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CONST_DIR', 'I-CONST_DIR', 'B-LIMIT', 'O', 'O', 'O', 'B-VAR', 'O', 'B-LIMIT', 'O', 'O', 'O', 'B-VAR', 'I-VAR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CONST_DIR', 'O', 'B-CONST_DIR', 'I-CONST_DIR', 'B-LIMIT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CONST_DIR', 'I-CONST_DIR', 'I-CONST_DIR', 'B-LIMIT', 'O', 'O', 'O', 'B-VAR', 'O', 'B-LIMIT', 'O', 'O', 'O', 'B-VAR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-VAR', 'I-VAR', 'O', 'O', 'B-OBJ_NAME', 'O', 'O', 'B-PARAM', 'O', 'O', 'O', 'O', 'O', 'B-VAR', 'I-VAR', 'O', 'O', 'O', 'B-PARAM', 'B-OBJ_NAME', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OBJ_DIR', 'O', 'O', 'O', 'B-OBJ_NAME', 'O']\n",
      "\n",
      "Tokens: ['John', 'has', 'a', '300', 'acre', 'berry', 'farm', 'on', 'which', 'to', 'plant', 'blueberries', 'and', 'raspberries', '.', 'John', 'has', '$', '10000', 'to', 'spend', 'on', 'watering', 'and', '575', 'days', 'worth', 'of', 'labor', 'available', '.', 'For', 'each', 'acre', 'of', 'blueberries', ',', '6', 'days', 'worth', 'of', 'labor', 'and', '$', '22', 'in', 'watering', 'costs', 'is', 'required', '.', 'For', 'each', 'acre', 'of', 'raspberries', ',', '3', 'days', 'worth', 'of', 'labor', 'and', '$', '25', 'in', 'watering', 'costs', 'is', 'required', '.', 'The', 'profit', 'per', 'acre', 'of', 'blueberries', 'is', '$', '56', 'and', 'the', 'profit', 'per', 'acre', 'of', 'raspberries', 'is', '$', '75', '.', 'Formulate', 'an', 'LP', 'problem', 'in', 'order', 'to', 'maximize', 'profit', '.']\n",
      "Predicted Labels: ['O', 'O', 'O', 'B-LIMIT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-VAR', 'O', 'B-VAR', 'O', 'O', 'O', 'O', 'B-LIMIT', 'O', 'O', 'O', 'O', 'O', 'B-LIMIT', 'O', 'O', 'O', 'O', 'B-CONST_DIR', 'O', 'O', 'O', 'O', 'O', 'B-VAR', 'O', 'B-PARAM', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PARAM', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-VAR', 'O', 'B-PARAM', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PARAM', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OBJ_NAME', 'O', 'O', 'O', 'B-VAR', 'O', 'O', 'B-PARAM', 'O', 'O', 'B-OBJ_NAME', 'O', 'O', 'O', 'B-VAR', 'O', 'O', 'B-PARAM', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OBJ_DIR', 'B-OBJ_NAME', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForTokenClassification,\n",
    "                          DataCollatorForTokenClassification,\n",
    "                          TrainingArguments,\n",
    "                          Trainer)\n",
    "import evaluate\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Helper function to read CoNLL format data from a file.\n",
    "# Each sentence is separated by an empty line.\n",
    "# Assumes token is in the first column and the entity tag in the last column.\n",
    "# ----------------------------------------------------------\n",
    "def read_conll(filename):\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":  # end of sentence\n",
    "                if tokens:\n",
    "                    sentences.append(tokens)\n",
    "                    tags.append(labels)\n",
    "                    tokens = []\n",
    "                    labels = []\n",
    "            else:\n",
    "                # split line; token is first, tag is last column\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:\n",
    "                    tokens.append(parts[0])\n",
    "                    labels.append(parts[-1])\n",
    "        if tokens:  # if last sentence is not followed by a newline\n",
    "            sentences.append(tokens)\n",
    "            tags.append(labels)\n",
    "    return sentences, tags\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load the train, dev, and test data from files.\n",
    "# ----------------------------------------------------------\n",
    "train_tokens, train_tags = read_conll(r\"D:\\LLM\\DATA\\train.txt\")\n",
    "dev_tokens, dev_tags = read_conll(r\"D:\\LLM\\DATA\\dev.txt\")\n",
    "test_tokens, test_tags = read_conll(r\"D:\\LLM\\DATA\\test.txt\")\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"tokens\": train_tokens, \"labels\": train_tags})\n",
    "dev_dataset   = Dataset.from_dict({\"tokens\": dev_tokens, \"labels\": dev_tags})\n",
    "test_dataset  = Dataset.from_dict({\"tokens\": test_tokens, \"labels\": test_tags})\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": dev_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Build the label mapping.\n",
    "# We extract the set of all unique labels from the training set.\n",
    "# ----------------------------------------------------------\n",
    "unique_labels = set()\n",
    "for seq in train_tags:\n",
    "    unique_labels.update(seq)\n",
    "label_list = sorted(list(unique_labels))\n",
    "label_to_id = {label: idx for idx, label in enumerate(label_list)}\n",
    "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
    "\n",
    "print(\"Label set:\", label_list)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load the XLM-RoBERTa tokenizer.\n",
    "# ----------------------------------------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Tokenize the data and align the labels.\n",
    "# For sub-word tokens, we assign a label only to the first sub-token and -100 to the remaining (ignored in loss).\n",
    "# ----------------------------------------------------------\n",
    "def tokenize_and_align_labels(batch):\n",
    "    tokenized_inputs = tokenizer(batch[\"tokens\"],\n",
    "                                 truncation=True,\n",
    "                                 is_split_into_words=True)\n",
    "    all_labels = []\n",
    "    for i, labels in enumerate(batch[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_to_id[labels[word_idx]])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        all_labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Apply the tokenization to the entire dataset.\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load the XLM-RoBERTa-base model for token classification.\n",
    "# Set the number of output labels and provide label mappings.\n",
    "# ----------------------------------------------------------\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"xlm-roberta-base\",\n",
    "                                                        num_labels=len(label_list),\n",
    "                                                        id2label=id_to_label,\n",
    "                                                        label2id=label_to_id)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Define training arguments.\n",
    "# ----------------------------------------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./xlm_roberta_token_classification\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\"  # or remove if your version does not support it either\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Define the data collator for token classification.\n",
    "# It dynamically pads the input sequences.\n",
    "# ----------------------------------------------------------\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Define the evaluation metric using the seqeval library.\n",
    "# ----------------------------------------------------------\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [id_to_label[pred] for pred, label in zip(prediction, label_seq) if label != -100]\n",
    "        for prediction, label_seq in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id_to_label[label] for pred, label in zip(prediction, label_seq) if label != -100]\n",
    "        for prediction, label_seq in zip(predictions, labels)\n",
    "    ]\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Initialize the Trainer.\n",
    "# ----------------------------------------------------------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Train the model.\n",
    "# ----------------------------------------------------------\n",
    "trainer.train()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Evaluate the model on the test set.\n",
    "# ----------------------------------------------------------\n",
    "test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(\"Test set evaluation:\", test_results)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# (Optional) Predict on the test set.\n",
    "# ----------------------------------------------------------\n",
    "predictions, _, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# (Optional) Post-process and print a few example predictions.\n",
    "for i in range(3):\n",
    "    tokens = tokenized_datasets[\"test\"][i][\"tokens\"]\n",
    "    pred_label_ids = predictions[i]\n",
    "    # Convert sub-token predictions back to word-level labels.\n",
    "    word_ids = tokenized_datasets[\"test\"][i].get(\"word_ids\", None)\n",
    "    if word_ids is None:\n",
    "        # If word_ids are not stored, re-run tokenizer for the single example.\n",
    "        encoded = tokenizer(tokens, is_split_into_words=True)\n",
    "        word_ids = encoded.word_ids()\n",
    "    word_preds = []\n",
    "    previous = None\n",
    "    for idx, word_idx in enumerate(word_ids):\n",
    "        if word_idx is None:\n",
    "            continue\n",
    "        if word_idx != previous:\n",
    "            word_preds.append(id_to_label[pred_label_ids[idx]])\n",
    "            previous = word_idx\n",
    "    print(\"Tokens:\", tokens)\n",
    "    print(\"Predicted Labels:\", word_preds)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac89f6a-1eea-4e45-a576-9aa6f211e0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./xlmr_lp_model_1\\\\tokenizer_config.json',\n",
       " './xlmr_lp_model_1\\\\special_tokens_map.json',\n",
       " './xlmr_lp_model_1\\\\tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer to the specified directory\n",
    "model.save_pretrained(\"./xlmr_lp_model_1\")\n",
    "tokenizer.save_pretrained(\"./xlmr_lp_model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac39b466-834a-4281-9c5f-2fe9874b4b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted data written to D:\\LLM\\NER\\nl4opt-subtask1-baseline\\train_subtask2_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_conll(filename):\n",
    "    \"\"\"\n",
    "    Reads a file in CoNLL format.\n",
    "    Returns a list of examples where each example is a tuple:\n",
    "      (tokens, labels)\n",
    "    Tokens: list of tokens (strings)\n",
    "    Labels: list of corresponding BIO labels\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":  # blank line indicates end of a sentence/example\n",
    "                if tokens:\n",
    "                    examples.append((tokens, labels))\n",
    "                    tokens = []\n",
    "                    labels = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:\n",
    "                    tokens.append(parts[0])\n",
    "                    labels.append(parts[-1])\n",
    "        if tokens:  # add last sentence if file does not end with a newline\n",
    "            examples.append((tokens, labels))\n",
    "    return examples\n",
    "\n",
    "def extract_entities(tokens, labels):\n",
    "    \"\"\"\n",
    "    Converts BIO tags into a list of entities.\n",
    "    Each entity is represented as a dictionary with:\n",
    "      - \"entity_type\": the entity category (without the \"B-\" or \"I-\" prefix)\n",
    "      - \"entity\": the concatenated token span (joined by a space)\n",
    "      - \"start\": the start token index in the sentence (optional)\n",
    "      - \"end\": the end token index (exclusive; optional)\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    entity = None\n",
    "    start_idx = None\n",
    "    for idx, (token, tag) in enumerate(zip(tokens, labels)):\n",
    "        if tag == \"O\":\n",
    "            # If we were in an entity, save it\n",
    "            if entity is not None:\n",
    "                entities.append({\n",
    "                    \"entity_type\": entity,\n",
    "                    \"entity\": \" \".join(current_tokens),\n",
    "                    \"start\": start_idx,\n",
    "                    \"end\": idx\n",
    "                })\n",
    "                entity = None\n",
    "                current_tokens = []\n",
    "            continue\n",
    "\n",
    "        # Split tag into prefix and entity type, e.g., \"B-VAR\" -> (\"B\", \"VAR\")\n",
    "        try:\n",
    "            prefix, ent_type = tag.split(\"-\", 1)\n",
    "        except ValueError:\n",
    "            # In case the tag does not follow the conventional format; skip it.\n",
    "            continue\n",
    "\n",
    "        if prefix == \"B\":  # beginning of a new entity span\n",
    "            if entity is not None:  # save the previous entity span\n",
    "                entities.append({\n",
    "                    \"entity_type\": entity,\n",
    "                    \"entity\": \" \".join(current_tokens),\n",
    "                    \"start\": start_idx,\n",
    "                    \"end\": idx\n",
    "                })\n",
    "            entity = ent_type\n",
    "            current_tokens = [token]\n",
    "            start_idx = idx\n",
    "        elif prefix == \"I\" and entity == ent_type:\n",
    "            # Continuation of an entity span\n",
    "            current_tokens.append(token)\n",
    "        else:\n",
    "            # Case: tag inconsistency (e.g., I- tag that doesnâ€™t match the previous B- tag).\n",
    "            # We start a new entity span.\n",
    "            if entity is not None:\n",
    "                entities.append({\n",
    "                    \"entity_type\": entity,\n",
    "                    \"entity\": \" \".join(current_tokens),\n",
    "                    \"start\": start_idx,\n",
    "                    \"end\": idx\n",
    "                })\n",
    "            entity = ent_type\n",
    "            current_tokens = [token]\n",
    "            start_idx = idx\n",
    "\n",
    "    # Catch any remaining entity at the end of the sentence\n",
    "    if entity is not None:\n",
    "        entities.append({\n",
    "            \"entity_type\": entity,\n",
    "            \"entity\": \" \".join(current_tokens),\n",
    "            \"start\": start_idx,\n",
    "            \"end\": len(tokens)\n",
    "        })\n",
    "    return entities\n",
    "\n",
    "def convert_to_subtask2_format(conll_filename, output_filename):\n",
    "    \"\"\"\n",
    "    Reads CoNLL-formatted data (sub-task 1 training data) and converts it to the format\n",
    "    expected by sub-task 2. For each example, it produces a JSON object with:\n",
    "      - \"problem_description\": the full natural language text (tokens joined together)\n",
    "      - \"entities\": a list of problem entities extracted using the BIO tags.\n",
    "    Saves the results in JSON Lines format.\n",
    "    \"\"\"\n",
    "    examples = read_conll(conll_filename)\n",
    "    with open(output_filename, 'w', encoding='utf-8') as out_file:\n",
    "        for tokens, labels in examples:\n",
    "            problem_description = \" \".join(tokens)\n",
    "            entities = extract_entities(tokens, labels)\n",
    "            # Create a dict matching the expected sub-task 2 input format.\n",
    "            # (If needed, you can also add an \"order_mapping\" field here.)\n",
    "            formatted_example = {\n",
    "                \"problem_description\": problem_description,\n",
    "                \"entities\": entities\n",
    "            }\n",
    "            out_file.write(json.dumps(formatted_example) + \"\\n\")\n",
    "\n",
    "# Example usage:\n",
    "conll_train_file = r\"D:\\LLM\\NER\\nl4opt-subtask1-baseline\\test_output.conll\"      # sub-task 1 data (CoNLL format)\n",
    "output_jsonl_file = r\"D:\\LLM\\NER\\nl4opt-subtask1-baseline\\train_subtask2_test.jsonl\"  # desired output format for sub-task 2\n",
    "\n",
    "convert_to_subtask2_format(conll_train_file, output_jsonl_file)\n",
    "print(f\"Converted data written to {output_jsonl_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fc35773-56bc-456a-9bad-aeebb6308582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete. Output saved to D:\\LLM\\NER\\nl4opt-subtask1-baseline\\train_subtask2_test_2.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_conll(filename):\n",
    "    \"\"\"\n",
    "    Reads a CoNLL-formatted file.\n",
    "    Returns a list of examples; each example is a tuple (tokens, labels).\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:  # empty line signals end of one example\n",
    "                if tokens:\n",
    "                    examples.append((tokens, labels))\n",
    "                    tokens = []\n",
    "                    labels = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                # Assuming the token is the first column and the tag is the last.\n",
    "                if len(parts) >= 2:\n",
    "                    tokens.append(parts[0])\n",
    "                    labels.append(parts[-1])\n",
    "        if tokens:\n",
    "            examples.append((tokens, labels))\n",
    "    return examples\n",
    "\n",
    "def extract_entities(tokens, labels):\n",
    "    \"\"\"\n",
    "    Extracts entity spans from a token list with BIO tags.\n",
    "    Each entity is returned as a dictionary containing:\n",
    "       - \"text\": the concatenated tokens (joined with a space)\n",
    "       - \"token_start\": the index of the first token of the entity\n",
    "       - \"token_end\": the index (exclusive) of the entity\n",
    "       - \"start\": the character start (here, we use token_start as a proxy)\n",
    "       - \"end\": the character end (here, we use token_end as a proxy)\n",
    "       - \"label\": the entity type (without the B- or I- prefix)\n",
    "    \"\"\"\n",
    "    spans = []\n",
    "    current_entity = None\n",
    "    current_tokens = []\n",
    "    start_idx = None\n",
    "\n",
    "    for idx, (token, tag) in enumerate(zip(tokens, labels)):\n",
    "        if tag == \"O\":\n",
    "            if current_entity is not None:\n",
    "                spans.append({\n",
    "                    \"text\": \" \".join(current_tokens),\n",
    "                    \"token_start\": start_idx,\n",
    "                    \"token_end\": idx,\n",
    "                    \"start\": start_idx,  # simplified proxy for character offset\n",
    "                    \"end\": idx,\n",
    "                    \"label\": current_entity\n",
    "                })\n",
    "                current_entity = None\n",
    "                current_tokens = []\n",
    "                start_idx = None\n",
    "            continue\n",
    "\n",
    "        # Split tag: e.g., \"B-VAR\" -> prefix \"B\", entity \"VAR\"\n",
    "        try:\n",
    "            prefix, ent_type = tag.split(\"-\", 1)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        if prefix == \"B\":\n",
    "            if current_entity is not None:\n",
    "                # Save previous entity span\n",
    "                spans.append({\n",
    "                    \"text\": \" \".join(current_tokens),\n",
    "                    \"token_start\": start_idx,\n",
    "                    \"token_end\": idx,\n",
    "                    \"start\": start_idx,\n",
    "                    \"end\": idx,\n",
    "                    \"label\": current_entity\n",
    "                })\n",
    "            current_entity = ent_type\n",
    "            current_tokens = [token]\n",
    "            start_idx = idx\n",
    "        elif prefix == \"I\" and current_entity == ent_type:\n",
    "            current_tokens.append(token)\n",
    "        else:\n",
    "            # If the tag doesn't follow the expected sequence, end the previous span and start a new one.\n",
    "            if current_entity is not None:\n",
    "                spans.append({\n",
    "                    \"text\": \" \".join(current_tokens),\n",
    "                    \"token_start\": start_idx,\n",
    "                    \"token_end\": idx,\n",
    "                    \"start\": start_idx,\n",
    "                    \"end\": idx,\n",
    "                    \"label\": current_entity\n",
    "                })\n",
    "            current_entity = ent_type\n",
    "            current_tokens = [token]\n",
    "            start_idx = idx\n",
    "\n",
    "    # End of sentence: add remaining entity if any.\n",
    "    if current_entity is not None:\n",
    "        spans.append({\n",
    "            \"text\": \" \".join(current_tokens),\n",
    "            \"token_start\": start_idx,\n",
    "            \"token_end\": len(tokens),\n",
    "            \"start\": start_idx,\n",
    "            \"end\": len(tokens),\n",
    "            \"label\": current_entity\n",
    "        })\n",
    "    return spans\n",
    "\n",
    "def build_order_mapping(vars_list):\n",
    "    \"\"\"\n",
    "    Creates a mapping from a canonical variable name (from vars_list) to its order index.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    for idx, var in enumerate(vars_list):\n",
    "        mapping[var] = idx\n",
    "    return mapping\n",
    "\n",
    "def convert_subtask1_to_subtask2(conll_filename, output_filename):\n",
    "    \"\"\"\n",
    "    Converts sub-task 1 output (in CoNLL format) to sub-task 2 input format (JSON format).\n",
    "    The output JSON object contains:\n",
    "      - \"document\": the original problem description (tokens joined into one string)\n",
    "      - \"tokens\": the token list\n",
    "      - \"spans\": the extracted entity spans (each a dict with text, token_start, token_end, etc.)\n",
    "      - \"vars\": a list of unique variable names (from spans labeled \"VAR\")\n",
    "      - \"var_mentions\": a list (in order) of all variable mentions (all spans with label \"VAR\")\n",
    "      - \"params\": a list of all parameters (from spans labeled \"PARAM\")\n",
    "      - \"var_mention_to_first_var\": mapping from each variable mention to the first occurrence\n",
    "      - \"first_var_to_mentions\": reverse mapping from canonical variable to list of mentions\n",
    "      - \"obj_declaration\": a stub example built from available objective spans (labels \"OBJ_DIR\" and \"OBJ_NAME\") and parameters\n",
    "      - \"const_declarations\": a stub list built from constraint spans (\"CONST_DIR\" and \"LIMIT\")\n",
    "      - \"order_mapping\": mapping of each variable (canonical) to an order index\n",
    "    The top-level JSON object is keyed by a unique id (here we use hash(document)).\n",
    "    \"\"\"\n",
    "    examples = read_conll(conll_filename)\n",
    "    output_dict = {}\n",
    "    \n",
    "    for tokens, labels in examples:\n",
    "        document = \" \".join(tokens)\n",
    "        spans = extract_entities(tokens, labels)\n",
    "        \n",
    "        # Collect variables and parameters from spans.\n",
    "        vars_list = []\n",
    "        var_mentions = []\n",
    "        params = []\n",
    "        for span in spans:\n",
    "            if span[\"label\"] == \"VAR\":\n",
    "                var_mentions.append(span[\"text\"])\n",
    "                if span[\"text\"] not in vars_list:\n",
    "                    vars_list.append(span[\"text\"])\n",
    "            elif span[\"label\"] == \"PARAM\":\n",
    "                params.append(span[\"text\"])\n",
    "                \n",
    "        # Create mapping: for each var mention, map to its first occurrence.\n",
    "        var_mention_to_first_var = {}\n",
    "        first_var_to_mentions = {}\n",
    "        for mention in var_mentions:\n",
    "            if mention not in var_mention_to_first_var:\n",
    "                var_mention_to_first_var[mention] = mention\n",
    "                first_var_to_mentions[mention] = [mention]\n",
    "            else:\n",
    "                first_var_to_mentions[mention].append(mention)\n",
    "                \n",
    "        # Stub: Build objective declaration from spans with label OBJ_DIR and OBJ_NAME.\n",
    "        obj_dir = None\n",
    "        obj_name = None\n",
    "        for span in spans:\n",
    "            if span[\"label\"] == \"OBJ_DIR\":\n",
    "                obj_dir = span[\"text\"]\n",
    "            elif span[\"label\"] == \"OBJ_NAME\":\n",
    "                if not obj_name:\n",
    "                    obj_name = span[\"text\"]\n",
    "                else:\n",
    "                    obj_name += \" \" + span[\"text\"]\n",
    "        # For terms, we map each variable to a parameter if available.\n",
    "        terms = {}\n",
    "        if params and vars_list:\n",
    "            # This is a simple heuristic: assign the first PARAM to the first variable, etc.\n",
    "            for i, var in enumerate(vars_list):\n",
    "                if i < len(params):\n",
    "                    terms[var] = params[i]\n",
    "        obj_declaration = {\n",
    "            \"type\": \"objective\",\n",
    "            \"direction\": obj_dir if obj_dir else \"\",\n",
    "            \"name\": obj_name if obj_name else \"\",\n",
    "            \"terms\": terms\n",
    "        }\n",
    "        \n",
    "        # Stub: Build a list of constraint declarations.\n",
    "        const_declarations = []\n",
    "        # For every span with label CONST_DIR, try to pair with a nearby LIMIT span.\n",
    "        for span in spans:\n",
    "            if span[\"label\"] == \"CONST_DIR\":\n",
    "                # Look ahead for a LIMIT span after this.\n",
    "                for span2 in spans:\n",
    "                    if span2[\"label\"] == \"LIMIT\" and span2[\"token_start\"] > span[\"token_start\"]:\n",
    "                        # Simple heuristic: if we have a CONST_DIR followed by a LIMIT, create a constraint.\n",
    "                        # Decide the type of constraint (e.g., \"sum\" or \"ratio\") based on the text of CONST_DIR.\n",
    "                        const_declarations.append({\n",
    "                            \"type\": \"ratio\" if \"minimum\" in span[\"text\"].lower() or \"no more than\" in span[\"text\"].lower() else \"sum\",\n",
    "                            \"direction\": span[\"text\"],\n",
    "                            \"limit\": span2[\"text\"],\n",
    "                            # In a more complete solution, you would also assign a variable for ratio constraints.\n",
    "                            \"operator\": \"GREATER_OR_EQUAL\" if \"minimum\" in span[\"text\"].lower() else \"LESS_OR_EQUAL\"\n",
    "                        })\n",
    "                        break\n",
    "        \n",
    "        # Determine the order mapping for variables.\n",
    "        order_mapping = build_order_mapping(vars_list)\n",
    "        \n",
    "        # Build the JSON object for this example.\n",
    "        example_json = {\n",
    "            \"document\": document,\n",
    "            \"tokens\": tokens,\n",
    "            \"spans\": spans,\n",
    "            \"vars\": vars_list,\n",
    "            \"var_mentions\": var_mentions,\n",
    "            \"params\": params,\n",
    "            \"var_mention_to_first_var\": var_mention_to_first_var,\n",
    "            \"first_var_to_mentions\": first_var_to_mentions,\n",
    "            \"obj_declaration\": obj_declaration,\n",
    "            \"const_declarations\": const_declarations,\n",
    "            \"order_mapping\": order_mapping\n",
    "        }\n",
    "        \n",
    "        # Use a unique id key for this document (for example, using the hash of the document).\n",
    "        doc_id = str(hash(document))\n",
    "        output_dict[doc_id] = example_json\n",
    "\n",
    "    # Save the output as a single JSON object (or use JSON Lines as needed)\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        json.dump(output_dict, out_file, indent=2)\n",
    "\n",
    "# Example usage:\n",
    "conll_train_file = r\"D:\\LLM\\NER\\nl4opt-subtask1-baseline\\test_output.conll\"          # Sub-task 1 data in CoNLL format\n",
    "output_jsonl_file = r\"D:\\LLM\\NER\\nl4opt-subtask1-baseline\\train_subtask2_test_2.jsonl\"  # Output file for sub-task 2 input\n",
    "\n",
    "convert_subtask1_to_subtask2(conll_train_file, output_jsonl_file)\n",
    "print(f\"Conversion complete. Output saved to {output_jsonl_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37749f72-5aec-48b0-a1a4-86232ff3aacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-DOCSTART-\t_\t_\tO\n",
      "\n",
      "Cautious\t_\t_\tO\n",
      "Asset\t_\t_\tO\n",
      "Investment\t_\t_\tO\n",
      "has\t_\t_\tO\n",
      "a\t_\t_\tO\n",
      "total\t_\t_\tO\n",
      "of\t_\t_\tO\n",
      "$150,000\t_\t_\tO\n",
      "to\t_\t_\tO\n",
      "manage\t_\t_\tO\n",
      "and\t_\t_\tO\n",
      "decides\t_\t_\tO\n",
      "to\t_\t_\tO\n",
      "invest\t_\t_\tO\n",
      "it\t_\t_\tO\n",
      "in\t_\t_\tO\n",
      "money\t_\t_\tB-VAR\n",
      "market\t_\t_\tI-VAR\n",
      "fund,\t_\t_\tI-VAR\n",
      "which\t_\t_\tO\n",
      "yields\t_\t_\tO\n",
      "a\t_\t_\tO\n",
      "2%\t_\t_\tB-PARAM\n",
      "return\t_\t_\tB-OBJ_NAME\n",
      "as\t_\t_\tO\n",
      "well\t_\t_\tO\n",
      "as\t_\t_\tO\n",
      "in\t_\t_\tO\n",
      "foreign\t_\t_\tB-VAR\n",
      "bonds,\t_\t_\tI-VAR\n",
      "which\t_\t_\tO\n",
      "gives\t_\t_\tO\n",
      "and\t_\t_\tO\n",
      "average\t_\t_\tO\n",
      "rate\t_\t_\tO\n",
      "of\t_\t_\tO\n",
      "return\t_\t_\tB-OBJ_NAME\n",
      "of\t_\t_\tO\n",
      "10.2%.\t_\t_\tB-PARAM\n",
      "Internal\t_\t_\tO\n",
      "policies\t_\t_\tO\n",
      "require\t_\t_\tO\n",
      "PAI\t_\t_\tO\n",
      "to\t_\t_\tO\n",
      "diversify\t_\t_\tO\n",
      "the\t_\t_\tO\n",
      "asset\t_\t_\tO\n",
      "allocation\t_\t_\tO\n",
      "so\t_\t_\tO\n",
      "that\t_\t_\tO\n",
      "the\t_\t_\tO\n",
      "minimum\t_\t_\tB-CONST_DIR\n",
      "investment\t_\t_\tO\n",
      "in\t_\t_\tO\n",
      "money\t_\t_\tB-VAR\n",
      "market\t_\t_\tI-VAR\n",
      "fund\t_\t_\tI-VAR\n",
      "is\t_\t_\tO\n",
      "40%\t_\t_\tB-LIMIT\n",
      "of\t_\t_\tO\n",
      "the\t_\t_\tO\n",
      "total\t_\t_\tO\n",
      "investment.\t_\t_\tO\n",
      "Due\t_\t_\tO\n",
      "to\t_\t_\tO\n",
      "the\t_\t_\tO\n",
      "risk\t_\t_\tO\n",
      "of\t_\t_\tO\n",
      "default\t_\t_\tO\n",
      "of\t_\t_\tO\n",
      "foreign\t_\t_\tO\n",
      "countries,\t_\t_\tO\n",
      "no\t_\t_\tB-CONST_DIR\n",
      "more\t_\t_\tI-CONST_DIR\n",
      "than\t_\t_\tI-CONST_DIR\n",
      "40%\t_\t_\tB-LIMIT\n",
      "of\t_\t_\tO\n",
      "the\t_\t_\tO\n",
      "total\t_\t_\tO\n",
      "investment\t_\t_\tO\n",
      "should\t_\t_\tO\n",
      "be\t_\t_\tO\n",
      "allocated\t_\t_\tO\n",
      "to\t_\t_\tO\n",
      "foreign\t_\t_\tB-VAR\n",
      "bonds.\t_\t_\tI-VAR\n",
      "How\t_\t_\tO\n",
      "much\t_\t_\tO\n",
      "should\t_\t_\tO\n",
      "the\t_\t_\tO\n",
      "Cautious\t_\t_\tO\n",
      "Asset\t_\t_\tO\n",
      "Investment\t_\t_\tO\n",
      "allocate\t_\t_\tO\n",
      "in\t_\t_\tO\n",
      "each\t_\t_\tO\n",
      "asset\t_\t_\tO\n",
      "so\t_\t_\tO\n",
      "as\t_\t_\tO\n",
      "to\t_\t_\tO\n",
      "maximize\t_\t_\tB-OBJ_DIR\n",
      "its\t_\t_\tO\n",
      "average\t_\t_\tO\n",
      "return?\t_\t_\tB-OBJ_NAME\n"
     ]
    }
   ],
   "source": [
    "print(conll_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9787cb8a-f126-40f3-9ec5-6bbc7e9ade81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 1; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataset = \u001b[43mDatasetDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconll_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: dictionary update sequence element #0 has length 1; 2 is required"
     ]
    }
   ],
   "source": [
    "dataset = DatasetDict(conll_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a1efe79-252f-4cc0-ad1c-93b4ac764c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(conll_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e39d907e-6831-43e2-8301-fe990f53b33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-DOCSTART-\\t_\\t_\\tO\\n\\nCautious\\t_\\t_\\tO\\nAsset\\t_\\t_\\tO\\nInvestment\\t_\\t_\\tO\\nhas\\t_\\t_\\tO\\na\\t_\\t_\\tO\\ntotal\\t_\\t_\\tO\\nof\\t_\\t_\\tO\\n$150,000\\t_\\t_\\tO\\nto\\t_\\t_\\tO\\nmanage\\t_\\t_\\tO\\nand\\t_\\t_\\tO\\ndecides\\t_\\t_\\tO\\nto\\t_\\t_\\tO\\ninvest\\t_\\t_\\tO\\nit\\t_\\t_\\tO\\nin\\t_\\t_\\tO\\nmoney\\t_\\t_\\tB-VAR\\nmarket\\t_\\t_\\tI-VAR\\nfund,\\t_\\t_\\tI-VAR\\nwhich\\t_\\t_\\tO\\nyields\\t_\\t_\\tO\\na\\t_\\t_\\tO\\n2%\\t_\\t_\\tB-PARAM\\nreturn\\t_\\t_\\tB-OBJ_NAME\\nas\\t_\\t_\\tO\\nwell\\t_\\t_\\tO\\nas\\t_\\t_\\tO\\nin\\t_\\t_\\tO\\nforeign\\t_\\t_\\tB-VAR\\nbonds,\\t_\\t_\\tI-VAR\\nwhich\\t_\\t_\\tO\\ngives\\t_\\t_\\tO\\nand\\t_\\t_\\tO\\naverage\\t_\\t_\\tO\\nrate\\t_\\t_\\tO\\nof\\t_\\t_\\tO\\nreturn\\t_\\t_\\tB-OBJ_NAME\\nof\\t_\\t_\\tO\\n10.2%.\\t_\\t_\\tB-PARAM\\nInternal\\t_\\t_\\tO\\npolicies\\t_\\t_\\tO\\nrequire\\t_\\t_\\tO\\nPAI\\t_\\t_\\tO\\nto\\t_\\t_\\tO\\ndiversify\\t_\\t_\\tO\\nthe\\t_\\t_\\tO\\nasset\\t_\\t_\\tO\\nallocation\\t_\\t_\\tO\\nso\\t_\\t_\\tO\\nthat\\t_\\t_\\tO\\nthe\\t_\\t_\\tO\\nminimum\\t_\\t_\\tB-CONST_DIR\\ninvestment\\t_\\t_\\tO\\nin\\t_\\t_\\tO\\nmoney\\t_\\t_\\tB-VAR\\nmarket\\t_\\t_\\tI-VAR\\nfund\\t_\\t_\\tI-VAR\\nis\\t_\\t_\\tO\\n40%\\t_\\t_\\tB-LIMIT\\nof\\t_\\t_\\tO\\nthe\\t_\\t_\\tO\\ntotal\\t_\\t_\\tO\\ninvestment.\\t_\\t_\\tO\\nDue\\t_\\t_\\tO\\nto\\t_\\t_\\tO\\nthe\\t_\\t_\\tO\\nrisk\\t_\\t_\\tO\\nof\\t_\\t_\\tO\\ndefault\\t_\\t_\\tO\\nof\\t_\\t_\\tO\\nforeign\\t_\\t_\\tO\\ncountries,\\t_\\t_\\tO\\nno\\t_\\t_\\tB-CONST_DIR\\nmore\\t_\\t_\\tI-CONST_DIR\\nthan\\t_\\t_\\tI-CONST_DIR\\n40%\\t_\\t_\\tB-LIMIT\\nof\\t_\\t_\\tO\\nthe\\t_\\t_\\tO\\ntotal\\t_\\t_\\tO\\ninvestment\\t_\\t_\\tO\\nshould\\t_\\t_\\tO\\nbe\\t_\\t_\\tO\\nallocated\\t_\\t_\\tO\\nto\\t_\\t_\\tO\\nforeign\\t_\\t_\\tB-VAR\\nbonds.\\t_\\t_\\tI-VAR\\nHow\\t_\\t_\\tO\\nmuch\\t_\\t_\\tO\\nshould\\t_\\t_\\tO\\nthe\\t_\\t_\\tO\\nCautious\\t_\\t_\\tO\\nAsset\\t_\\t_\\tO\\nInvestment\\t_\\t_\\tO\\nallocate\\t_\\t_\\tO\\nin\\t_\\t_\\tO\\neach\\t_\\t_\\tO\\nasset\\t_\\t_\\tO\\nso\\t_\\t_\\tO\\nas\\t_\\t_\\tO\\nto\\t_\\t_\\tO\\nmaximize\\t_\\t_\\tB-OBJ_DIR\\nits\\t_\\t_\\tO\\naverage\\t_\\t_\\tO\\nreturn?\\t_\\t_\\tB-OBJ_NAME'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1134452-6b31-4b58-af88-55a2579e7a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 714 examples from D:\\LLM\\DATA\\train.txt\n",
      "Saved 714 examples to D:\\LLM\\DATA\\train_bart_ready_1.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# --- Helper: Read CoNLL data from file ---\n",
    "def read_conll(filename):\n",
    "    \"\"\"Read a CoNLL-format file and return a list of sentences and corresponding tag sequences.\"\"\"\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                if tokens:\n",
    "                    sentences.append(tokens)\n",
    "                    tags.append(labels)\n",
    "                    tokens = []\n",
    "                    labels = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:\n",
    "                    tokens.append(parts[0])\n",
    "                    labels.append(parts[-1])\n",
    "        if tokens:\n",
    "            sentences.append(tokens)\n",
    "            tags.append(labels)\n",
    "    return sentences, tags\n",
    "\n",
    "\n",
    "# --- Helper: Convert a BIO-tagged sentence to an XML-like annotated string ---\n",
    "def bio_to_xml(tokens, bio_tags):\n",
    "    \"\"\"\n",
    "    Convert tokens and their BIO tags to an XML-like annotated string.\n",
    "    For example, if tokens = ['A', 'foldable', 'cell-phone'] with tags\n",
    "      ['O', 'B-VAR', 'I-VAR'],\n",
    "    then the output might be \"A <VAR>foldable cell-phone</VAR>\".\n",
    "    \"\"\"\n",
    "    output_tokens = []\n",
    "    current_entity = None  # e.g., \"VAR\", \"CONSTR_DIR\", etc.\n",
    "\n",
    "    for token, tag in zip(tokens, bio_tags):\n",
    "        if tag == \"O\":\n",
    "            # close any open entity span\n",
    "            if current_entity is not None:\n",
    "                output_tokens[-1] += f\"</{current_entity}>\"\n",
    "                current_entity = None\n",
    "            output_tokens.append(token)\n",
    "        else:\n",
    "            # tag in BIO format; split into prefix and entity type\n",
    "            try:\n",
    "                prefix, entity_type = tag.split(\"-\")\n",
    "            except ValueError:\n",
    "                # If tag is malformed, treat as O.\n",
    "                if current_entity is not None:\n",
    "                    output_tokens[-1] += f\"</{current_entity}>\"\n",
    "                    current_entity = None\n",
    "                output_tokens.append(token)\n",
    "                continue\n",
    "\n",
    "            if prefix == \"B\":\n",
    "                # If an entity span is already open, close it first.\n",
    "                if current_entity is not None:\n",
    "                    output_tokens[-1] += f\"</{current_entity}>\"\n",
    "                # Open new entity span with the detected entity type.\n",
    "                output_tokens.append(f\"<{entity_type}>{token}\")\n",
    "                current_entity = entity_type\n",
    "            elif prefix == \"I\":\n",
    "                # Continue the entity span\n",
    "                if current_entity == entity_type:\n",
    "                    output_tokens.append(token)\n",
    "                else:\n",
    "                    # Inconsistent tag ordering; treat as beginning of new entity.\n",
    "                    if current_entity is not None:\n",
    "                        output_tokens[-1] += f\"</{current_entity}>\"\n",
    "                    output_tokens.append(f\"<{entity_type}>{token}\")\n",
    "                    current_entity = entity_type\n",
    "    # Close any open entity span at the end.\n",
    "    if current_entity is not None:\n",
    "        output_tokens[-1] += f\"</{current_entity}>\"\n",
    "    # Join tokens with a single space (or use your desired formatting).\n",
    "    return \" \".join(output_tokens)\n",
    "\n",
    "\n",
    "# --- Main script: Process train.txt and produce train_bart_ready_1.jsonl ---\n",
    "def main():\n",
    "    # Path to input file (CoNLL format) and output jsonl file.\n",
    "    input_file = r\"D:\\LLM\\DATA\\train.txt\"\n",
    "    output_file = r\"D:\\LLM\\DATA\\train_bart_ready_1.jsonl\"\n",
    "\n",
    "    # Read tokenized examples and their BIO tags.\n",
    "    sentences, tag_sequences = read_conll(input_file)\n",
    "    print(f\"Read {len(sentences)} examples from {input_file}\")\n",
    "\n",
    "    # Prepare a list of JSON objects\n",
    "    json_objects = []\n",
    "    for tokens, tags in zip(sentences, tag_sequences):\n",
    "        # Reconstruct the original (untokenized) text\n",
    "        # Here we assume that simply joining tokens with a space approximates the original text.\n",
    "        original_text = \" \".join(tokens)\n",
    "        # Convert the tokens/BIO tags to an XML-like annotation.\n",
    "        xml_annotation = bio_to_xml(tokens, tags)\n",
    "        # Prepare the JSON object â€“ here we assume the input for training BART is the XML-annotated text.\n",
    "        # You could also include fields for the target logical form if needed.\n",
    "        json_obj = {\n",
    "            \"input\": xml_annotation,\n",
    "            \"original_text\": original_text  # optionally include the original text for reference\n",
    "        }\n",
    "        json_objects.append(json_obj)\n",
    "\n",
    "    # Write out to a JSONL file.\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "        for obj in json_objects:\n",
    "            out_f.write(json.dumps(obj) + \"\\n\")\n",
    "\n",
    "    print(f\"Saved {len(json_objects)} examples to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cacd33d-13ad-4158-b060-dfc28a0bf0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output in CoNLL Format:\n",
      "\n",
      "-DOCSTART-\t_\t_\tO\n",
      "\n",
      "A\t_\t_\tO\n",
      "bubble\t_\t_\tO\n",
      "tea\t_\t_\tO\n",
      "store\t_\t_\tO\n",
      "sells\t_\t_\tO\n",
      "peach\t_\t_\tB-VAR\n",
      "and\t_\t_\tO\n",
      "mango\t_\t_\tB-VAR\n",
      "flavored\t_\t_\tO\n",
      "drinks.\t_\t_\tI-VAR\n",
      "The\t_\t_\tO\n",
      "store\t_\t_\tO\n",
      "can\t_\t_\tO\n",
      "make\t_\t_\tO\n",
      "at\t_\t_\tB-CONST_DIR\n",
      "most\t_\t_\tI-CONST_DIR\n",
      "788\t_\t_\tB-LIMIT\n",
      "drinks\t_\t_\tO\n",
      "in\t_\t_\tO\n",
      "total.\t_\t_\tO\n",
      "To\t_\t_\tO\n",
      "stay\t_\t_\tO\n",
      "in\t_\t_\tO\n",
      "business,\t_\t_\tO\n",
      "they\t_\t_\tO\n",
      "must\t_\t_\tO\n",
      "sell\t_\t_\tO\n",
      "at\t_\t_\tB-CONST_DIR\n",
      "least\t_\t_\tI-CONST_DIR\n",
      "53\t_\t_\tB-LIMIT\n",
      "mango\t_\t_\tB-VAR\n",
      "drinks\t_\t_\tI-VAR\n",
      "and\t_\t_\tO\n",
      "89\t_\t_\tB-LIMIT\n",
      "peach\t_\t_\tB-VAR\n",
      "drinks.\t_\t_\tI-VAR\n",
      "However,\t_\t_\tO\n",
      "due\t_\t_\tO\n",
      "to\t_\t_\tO\n",
      "fruit\t_\t_\tO\n",
      "shortages,\t_\t_\tO\n",
      "they\t_\t_\tO\n",
      "can\t_\t_\tO\n",
      "make\t_\t_\tO\n",
      "at\t_\t_\tB-CONST_DIR\n",
      "most\t_\t_\tI-CONST_DIR\n",
      "560\t_\t_\tB-LIMIT\n",
      "mango\t_\t_\tB-VAR\n",
      "drinks\t_\t_\tI-VAR\n",
      "and\t_\t_\tO\n",
      "at\t_\t_\tB-CONST_DIR\n",
      "most\t_\t_\tI-CONST_DIR\n",
      "64\t_\t_\tB-LIMIT\n",
      "peach\t_\t_\tB-VAR\n",
      "drinks.\t_\t_\tI-VAR\n",
      "The\t_\t_\tO\n",
      "profit\t_\t_\tB-OBJ_NAME\n",
      "per\t_\t_\tO\n",
      "mango\t_\t_\tB-VAR\n",
      "drink\t_\t_\tI-VAR\n",
      "is\t_\t_\tO\n",
      "$3,\t_\t_\tB-PARAM\n",
      "and\t_\t_\tO\n",
      "the\t_\t_\tO\n",
      "profit\t_\t_\tB-OBJ_NAME\n",
      "per\t_\t_\tO\n",
      "peach\t_\t_\tB-VAR\n",
      "drink\t_\t_\tI-VAR\n",
      "is\t_\t_\tO\n",
      "$1.\t_\t_\tB-PARAM\n",
      "How\t_\t_\tO\n",
      "many\t_\t_\tO\n",
      "of\t_\t_\tO\n",
      "each\t_\t_\tO\n",
      "drink\t_\t_\tO\n",
      "should\t_\t_\tO\n",
      "they\t_\t_\tO\n",
      "sell\t_\t_\tO\n",
      "to\t_\t_\tO\n",
      "maximize\t_\t_\tB-OBJ_DIR\n",
      "profit?\t_\t_\tB-OBJ_NAME\n",
      "\n",
      "Saved the predicted output to single_test_output-sub1.conll\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "# Load the post-trained XLM-RoBERTa model and tokenizer for sub-task 1\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"./xlmr_lp_model_1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./xlmr_lp_model_1\")\n",
    "\n",
    "def predict_entities(text: str, max_length=512):\n",
    "    \"\"\"\n",
    "    Given a plain-text optimization problem description, this function tokenizes the text,\n",
    "    runs the model to predict BIO tags, and returns two lists:\n",
    "      - words: the original tokens (word-level)\n",
    "      - predicted_tags: the predicted label for each word (taking the first sub-token only)\n",
    "    \"\"\"\n",
    "    # Simple whitespace tokenization: for sub-task 1 the input is a plain text description.\n",
    "    words = text.split()\n",
    "    \n",
    "    # Tokenize the list of words while preserving word boundaries.\n",
    "    encoded = tokenizer(words,\n",
    "                        is_split_into_words=True,\n",
    "                        return_tensors=\"pt\",\n",
    "                        truncation=True,\n",
    "                        max_length=max_length)\n",
    "    encoded = encoded.to(model.device)\n",
    "    \n",
    "    # Obtain logits from the model\n",
    "    with torch.no_grad():\n",
    "        logits = model(**encoded).logits  # shape: (1, seq_length, num_labels)\n",
    "    \n",
    "    # Choose the label with the highest logit for each token (sub-token)\n",
    "    predictions = np.argmax(logits.cpu().detach().numpy(), axis=2)[0]\n",
    "    \n",
    "    # Get the mapping of sub-tokens to original word indices.\n",
    "    word_ids = encoded.word_ids(batch_index=0)\n",
    "    \n",
    "    final_words = []\n",
    "    final_tags = []\n",
    "    previous_word_idx = None\n",
    "    for idx, word_idx in enumerate(word_ids):\n",
    "        if word_idx is None:\n",
    "            continue\n",
    "        # Only take the first sub-token for each word (to avoid duplicate labels for a single word)\n",
    "        if word_idx != previous_word_idx:\n",
    "            final_words.append(words[word_idx])\n",
    "            final_tags.append(model.config.id2label[predictions[idx]])\n",
    "            previous_word_idx = word_idx\n",
    "    return final_words, final_tags\n",
    "\n",
    "def get_conll_format(words, tags):\n",
    "    \"\"\"\n",
    "    Generate a string in CoNLL format with each token on a new line.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    # DOCSTART header.\n",
    "    lines.append(\"-DOCSTART-\\t_\\t_\\tO\\n\")\n",
    "    for word, tag in zip(words, tags):\n",
    "        lines.append(f\"{word}\\t_\\t_\\t{tag}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def save_conll_format(output_str, filename):\n",
    "    \"\"\"\n",
    "    Save the given CoNLL-style string to the specified file.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(output_str)\n",
    "\n",
    "# --- Sample Input for Sub-task 1 ---\n",
    "# For sub-task 1 the input is simply the problem description (without additional XML markup).\n",
    "sample_input = (\n",
    "    \"A bubble tea store sells peach and mango flavored drinks. The store can make at most 788 drinks in total. To stay in business, they must sell at least 53 mango drinks and 89 peach drinks. However, due to fruit shortages, they can make at most 560 mango drinks and at most 64 peach drinks. The profit per mango drink is $3, and the profit per peach drink is $1. How many of each drink should they sell to maximize profit?\"\n",
    ")\n",
    "\n",
    "# Get predictions from the model.\n",
    "words, predicted_tags = predict_entities(sample_input)\n",
    "\n",
    "# Convert the predictions to CoNLL format.\n",
    "conll_output = get_conll_format(words, predicted_tags)\n",
    "print(\"Predicted Output in CoNLL Format:\\n\")\n",
    "print(conll_output)\n",
    "\n",
    "# Save the output to a file.\n",
    "output_filename = \"single_test_output-sub1.conll\"\n",
    "save_conll_format(conll_output, output_filename)\n",
    "print(f\"\\nSaved the predicted output to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "262899b2-ada0-486f-ac91-3457160e48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python conll2bart_ready.py \\\n",
    "  --conll D:/LLM/NER/nl4opt-subtask1-baseline/single_test_output-sub1.conll \\\n",
    "  --out bart_inputs_single_test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99311f1-fde9-4052-9eed-cdcb6f993d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
